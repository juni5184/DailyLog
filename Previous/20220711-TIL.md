# 2022.07.11

### Tabular 데이터 처리 복습 (AIFB 준비)  
    ii. 머신러닝 퀴즈 - 헷갈리는 코드 

    - df['컬럼명'].value_counts().plot(kind='bar') : 판다스 value_counts와 plot 함수로 컬럼 불균형 확인하기  
    - pd.get_dummies(data = df, columns=['컬럼명']) : 판다스 get_dummies 함수 이용해서 컬럼 값을 원핫 인코딩 출력 
    - df.select_dtypes('object').head(3) : select_dtypes 함수 이용해서 Object 컬럼 확인(앞 3개 내용만 보기)
    - cal_cols = df.select_dtypes('object').columns.values : 판다스 select_dtypes 함수 이용해서 Object 컬럼명의 값(values) 수집해서 cal_cols에 저장하기
    - X = df1.drop('컬럼', axis = 1).values : df1 데이터프레임에서 컬럼 삭제 및 values만 X에 저장  
    - X.shape, y.shape : X, y 데이터에 대한 shape 확인하기
    - from sklearn.model_selection import train_test_split : sklearn.model_selection 하위에 있는 train_test_split 임포트
    - train_test_split test_size-0.3 옵션 : Train,Test 비율 7,3으로 나누기
    - train_test_split stratify 옵션 : 계층적 데이터 추출 옵션

    - from sklearn.preprocessing import MinMaxScaler : MinMaxScaler 함수 임포트 (sklearn.preprocessing 모듈 밑어 있음)
    - X_train = scaler.fit_transform(X_train) / X_test = scaler.transform(X_test) : X_train, X_test에 scaler(MinMaxScaler() 사용)

    - lg.score(X_test,y_test) : logistic regression 성능 평가 (test 데이터 넣어야 함)
    - lg_pred = lg.predict(X_test) : 예측 결과를 lg_pred에 저장
    - print(classification_report(y_test, lg_pred)) : classification_report 출력 -> precision, recall, f1-score

    - knn_pred = knn.predict(X_test) : X_test 예측 결과 knn_pred에 저장


머신러닝은 대체로 4가지 순서로 진행 됨
1. 임포트
2. 모델 정의
3. fit 학습
4. 예측  
+그래프 그리기

```python
from sklearn.neighbors import KNeighborsClassifier  
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)
recall_eval('K-Nearest Neighbor', knn_pred, y_test)
```